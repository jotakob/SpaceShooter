<!DOCTYPE html><html lang="en"><head><link href="http://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/css/bootstrap-combined.min.css" rel="stylesheet"></link><script src="http://code.jquery.com/jquery-1.9.1.min.js"></script><script src="http://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/js/bootstrap.min.js"></script><link href="/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages/styles.css" rel="stylesheet"></link><script type="text/javascript">var dox = {rootPath: "/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages",platforms: ["Linux","Mac","Tizen","Android","Windows","iOS","Flash","BlackBerry","Firefox","HTML5"]};</script><script type="text/javascript" src="/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages/nav.js"></script><script type="text/javascript" src="/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages/index.js"></script><link rel="icon" href="/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages/favicon.ico" type="image/x-icon"></link><title>InteractiveObject</title></head><body><div class="navbar navbar-inverse navbar-fixed-top"><div class="navbar-inner"><form class="navbar-search pull-left" id="searchForm"><input id="search" type="text" class="search-query" placeholder="Search" autocomplete="off"></input></form><ul class="nav"><li id="select-platform" class="dropdown"><a href="#" class="dropdown-toggle" data-toggle="dropdown">Platform<b class="caret"></b></a><ul class="dropdown-menu"><li data="all"><a href="#">All Platforms</a></li><li data="Linux"><a href="#">Linux</a></li><li data="Mac"><a href="#">Mac</a></li><li data="Tizen"><a href="#">Tizen</a></li><li data="Android"><a href="#">Android</a></li><li data="Windows"><a href="#">Windows</a></li><li data="iOS"><a href="#">iOS</a></li><li data="Flash"><a href="#">Flash</a></li><li data="BlackBerry"><a href="#">BlackBerry</a></li><li data="Firefox"><a href="#">Firefox</a></li><li data="HTML5"><a href="#">HTML5</a></li></ul></li></ul></div></div><div id="container"><div id="nav"></div><div id="content"><div class="header"><h1><code><span class="directive">class </span><span class="type">openfl.display.InteractiveObject</span><span class="keyword"> extends</span> <a class="type" href="/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages/openfl/display/DisplayObject.html">DisplayObject</a></code></h1></div><div class="body"><p class="availability">Available on  all platforms</p><div class="doc"><p>The InteractiveObject class is the abstract base class for all display
<em> objects with which the user can interact, using the mouse, keyboard, or
</em> other user input device.
<em>
</em> <p>You cannot instantiate the InteractiveObject class directly. A call to
<em> the <code>new InteractiveObject()</code> constructor throws an
</em> <code>ArgumentError</code> exception.</p>
<em>
</em> <p>The InteractiveObject class itself does not include any APIs for
<em> rendering content onscreen. To create a custom subclass of the
</em> InteractiveObject class, extend one of the subclasses that do have APIs for
<em> rendering content onscreen, such as the Sprite, SimpleButton, TextField, or
</em> MovieClip classes.</p>
<em> 
</em> @event clear                  Dispatched when the user selects 'Clear'(or
<em>                               'Delete') from the text context menu. This
</em>                               event is dispatched to the object that
<em>                               currently has focus. If the object that
</em>                               currently has focus is a TextField, the
<em>                               default behavior of this event is to cause
</em>                               any currently selected text in the text field
<em>                               to be deleted.
</em> @event click                  Dispatched when a user presses and releases
<em>                               the main button of the user's pointing device
</em>                               over the same InteractiveObject. For a click
<em>                               event to occur, it must always follow this
</em>                               series of events in the order of occurrence:
<em>                               mouseDown event, then mouseUp. The target
</em>                               object must be identical for both of these
<em>                               events; otherwise the <code>click</code>
</em>                               event does not occur. Any number of other
<em>                               mouse events can occur at any time between
</em>                               the <code>mouseDown</code> or
<em>                               <code>mouseUp</code> events; the
</em>                               <code>click</code> event still occurs.
<em> @event contextMenu            Dispatched when a user gesture triggers the
</em>                               context menu associated with this interactive
<em>                               object in an AIR application.
</em> @event copy                   Dispatched when the user activates the
<em>                               platform-specific accelerator key combination
</em>                               for a copy operation or selects 'Copy' from
<em>                               the text context menu. This event is
</em>                               dispatched to the object that currently has
<em>                               focus. If the object that currently has focus
</em>                               is a TextField, the default behavior of this
<em>                               event is to cause any currently selected text
</em>                               in the text field to be copied to the
<em>                               clipboard.
</em> @event cut                    Dispatched when the user activates the
<em>                               platform-specific accelerator key combination
</em>                               for a cut operation or selects 'Cut' from the
<em>                               text context menu. This event is dispatched
</em>                               to the object that currently has focus. If
<em>                               the object that currently has focus is a
</em>                               TextField, the default behavior of this event
<em>                               is to cause any currently selected text in
</em>                               the text field to be cut to the clipboard.
<em> @event doubleClick            Dispatched when a user presses and releases
</em>                               the main button of a pointing device twice in
<em>                               rapid succession over the same
</em>                               InteractiveObject when that object's
<em>                               <code>doubleClickEnabled</code> flag is set
</em>                               to <code>true</code>. For a
<em>                               <code>doubleClick</code> event to occur, it
</em>                               must immediately follow the following series
<em>                               of events: <code>mouseDown</code>,
</em>                               <code>mouseUp</code>, <code>click</code>,
<em>                               <code>mouseDown</code>, <code>mouseUp</code>.
</em>                               All of these events must share the same
<em>                               target as the <code>doubleClick</code> event.
</em>                               The second click, represented by the second
<em>                               <code>mouseDown</code> and
</em>                               <code>mouseUp</code> events, must occur
<em>                               within a specific period of time after the
</em>                               <code>click</code> event. The allowable
<em>                               length of this period varies by operating
</em>                               system and can often be configured by the
<em>                               user. If the target is a selectable text
</em>                               field, the word under the pointer is selected
<em>                               as the default behavior. If the target
</em>                               InteractiveObject does not have its
<em>                               <code>doubleClickEnabled</code> flag set to
</em>                               <code>true</code> it receives two
<em>                               <code>click</code> events.
</em>
<em>                               <p>The <code>doubleClickEnabled</code>
</em>                               property defaults to <code>false</code>. </p>
<em>
</em>                               <p>The double-click text selection behavior
<em>                               of a TextField object is not related to the
</em>                               <code>doubleClick</code> event. Use
<em>                               <code>TextField.doubleClickEnabled</code> to
</em>                               control TextField selections.</p>
<em> @event focusIn                Dispatched <i>after</i> a display object
</em>                               gains focus. This situation happens when a
<em>                               user highlights the object with a pointing
</em>                               device or keyboard navigation. The recipient
<em>                               of such focus is called the target object of
</em>                               this event, while the corresponding
<em>                               InteractiveObject instance that lost focus
</em>                               because of this change is called the related
<em>                               object. A reference to the related object is
</em>                               stored in the receiving object's
<em>                               <code>relatedObject</code> property. The
</em>                               <code>shiftKey</code> property is not used.
<em>                               This event follows the dispatch of the
</em>                               previous object's <code>focusOut</code>
<em>                               event.
</em> @event focusOut               Dispatched <i>after</i> a display object
<em>                               loses focus. This happens when a user
</em>                               highlights a different object with a pointing
<em>                               device or keyboard navigation. The object
</em>                               that loses focus is called the target object
<em>                               of this event, while the corresponding
</em>                               InteractiveObject instance that receives
<em>                               focus is called the related object. A
</em>                               reference to the related object is stored in
<em>                               the target object's
</em>                               <code>relatedObject</code> property. The
<em>                               <code>shiftKey</code> property is not used.
</em>                               This event precedes the dispatch of the
<em>                               <code>focusIn</code> event by the related
</em>                               object.
<em> @event gesturePan             Dispatched when the user moves a point of
</em>                               contact over the InteractiveObject instance
<em>                               on a touch-enabled device(such as moving a
</em>                               finger from left to right over a display
<em>                               object on a mobile phone or tablet with a
</em>                               touch screen). Some devices might also
<em>                               interpret this contact as a
</em>                               <code>mouseOver</code> event and as a
<em>                               <code>touchOver</code> event.
</em>
<em>                               <p>Specifically, if a user moves a finger
</em>                               over an InteractiveObject, the
<em>                               InteractiveObject instance can dispatch a
</em>                               <code>mouseOver</code> event or a
<em>                               <code>touchOver</code> event or a
</em>                               <code>gesturePan</code> event, or all if the
<em>                               current environment supports it. Choose how
</em>                               you want to handle the user interaction. Use
<em>                               the openfl.ui.Multitouch class to manage touch
</em>                               event handling(enable touch gesture event
<em>                               handling, simple touch point event handling,
</em>                               or disable touch events so only mouse events
<em>                               are dispatched). If you choose to handle the
</em>                               <code>mouseOver</code> event, then the same
<em>                               event handler will run on a touch-enabled
</em>                               device and a mouse enabled device. However,
<em>                               if you choose to handle the
</em>                               <code>gesturePan</code> event, you can design
<em>                               your event handler to respond to the specific
</em>                               needs of a touch-enabled environment and
<em>                               provide users with a richer touch-enabled
</em>                               experience. You can also handle both events,
<em>                               separately, to provide a different response
</em>                               for a touch event than a mouse event.</p>
<em>
</em>                               <p><b>Note:</b> See the Multitouch class for
<em>                               environment compatibility information.</p>
</em> @event gesturePressAndTap     Dispatched when the user creates a point of
<em>                               contact with an InteractiveObject instance,
</em>                               then taps on a touch-enabled device(such as
<em>                               placing several fingers over a display object
</em>                               to open a menu and then taps one finger to
<em>                               select a menu item on a mobile phone or
</em>                               tablet with a touch screen). Some devices
<em>                               might also interpret this contact as a
</em>                               combination of several mouse events, as well.
<em>
</em>
<em>                               <p>Specifically, if a user moves a finger
</em>                               over an InteractiveObject, and then provides
<em>                               a secondary tap, the InteractiveObject
</em>                               instance can dispatch a
<em>                               <code>mouseOver</code> event and a
</em>                               <code>click</code> event(among others) as
<em>                               well as the <code>gesturePressAndTap</code>
</em>                               event, or all if the current environment
<em>                               supports it. Choose how you want to handle
</em>                               the user interaction. Use the
<em>                               openfl.ui.Multitouch class to manage touch
</em>                               event handling(enable touch gesture event
<em>                               handling, simple touch point event handling,
</em>                               or disable touch events so only mouse events
<em>                               are dispatched). If you choose to handle the
</em>                               <code>mouseOver</code> event, then the same
<em>                               event handler will run on a touch-enabled
</em>                               device and a mouse enabled device. However,
<em>                               if you choose to handle the
</em>                               <code>gesturePressAndTap</code> event, you
<em>                               can design your event handler to respond to
</em>                               the specific needs of a touch-enabled
<em>                               environment and provide users with a richer
</em>                               touch-enabled experience. You can also handle
<em>                               both events, separately, to provide a
</em>                               different response for a touch event than a
<em>                               mouse event.</p>
</em>
<em>                               <p>When handling the properties of the event
</em>                               object, note that the <code>localX</code> and
<em>                               <code>localY</code> properties are set to the
</em>                               primary point of contact(the "push"). The
<em>                               <code>offsetX</code> and <code>offsetY</code>
</em>                               properties are the distance to the secondary
<em>                               point of contact(the "tap").</p>
</em> @event gestureRotate          Dispatched when the user performs a rotation
<em>                               gesture at a point of contact with an
</em>                               InteractiveObject instance(such as touching
<em>                               two fingers and rotating them over a display
</em>                               object on a mobile phone or tablet with a
<em>                               touch screen). Two-finger rotation is a
</em>                               common rotation gesture, but each device and
<em>                               operating system can have its own
</em>                               requirements to indicate rotation. Some
<em>                               devices might also interpret this contact as
</em>                               a combination of several mouse events, as
<em>                               well.
</em>
<em>                               <p>Specifically, if a user moves a finger
</em>                               over an InteractiveObject, the
<em>                               InteractiveObject instance can dispatch a
</em>                               <code>mouseOver</code> event and a
<em>                               <code>click</code> event(among others), in
</em>                               addition to the <code>gestureRotate</code>
<em>                               event, or all if the current environment
</em>                               supports it. Choose how you want to handle
<em>                               the user interaction. Use the
</em>                               openfl.ui.Multitouch class to manage touch
<em>                               event handling(enable touch gesture event
</em>                               handling, simple touch point event handling,
<em>                               or disable touch events so only mouse events
</em>                               are dispatched). If you choose to handle the
<em>                               <code>mouseOver</code> event, then the same
</em>                               event handler will run on a touch-enabled
<em>                               device and a mouse enabled device. However,
</em>                               if you choose to handle the
<em>                               <code>gestureRotate</code> event, you can
</em>                               design your event handler to respond to the
<em>                               specific needs of a touch-enabled environment
</em>                               and provide users with a richer touch-enabled
<em>                               experience. You can also handle both events,
</em>                               separately, to provide a different response
<em>                               for a touch event than a mouse event.</p>
</em>
<em>                               <p>When handling the properties of the event
</em>                               object, note that the <code>localX</code> and
<em>                               <code>localY</code> properties are set to the
</em>                               primary point of contact. The
<em>                               <code>offsetX</code> and <code>offsetY</code>
</em>                               properties are the distance to the point of
<em>                               contact where the rotation gesture is
</em>                               complete.</p>
<em>
</em>                               <p><b>Note:</b> See the Multitouch class for
<em>                               environment compatibility information.</p>
</em> @event gestureSwipe           Dispatched when the user performs a swipe
<em>                               gesture at a point of contact with an
</em>                               InteractiveObject instance(such as touching
<em>                               three fingers to a screen and then moving
</em>                               them in parallel over a display object on a
<em>                               mobile phone or tablet with a touch screen).
</em>                               Moving several fingers in parallel is a
<em>                               common swipe gesture, but each device and
</em>                               operating system can have its own
<em>                               requirements for a swipe. Some devices might
</em>                               also interpret this contact as a combination
<em>                               of several mouse events, as well.
</em>
<em>                               <p>Specifically, if a user moves a finger
</em>                               over an InteractiveObject, and then moves the
<em>                               fingers together, the InteractiveObject
</em>                               instance can dispatch a <code>rollOver</code>
<em>                               event and a <code>rollOut</code> event(among
</em>                               others), in addition to the
<em>                               <code>gestureSwipe</code> event, or all if
</em>                               the current environment supports it. Choose
<em>                               how you want to handle the user interaction.
</em>                               If you choose to handle the
<em>                               <code>rollOver</code> event, then the same
</em>                               event handler will run on a touch-enabled
<em>                               device and a mouse enabled device. However,
</em>                               if you choose to handle the
<em>                               <code>gestureSwipe</code> event, you can
</em>                               design your event handler to respond to the
<em>                               specific needs of a touch-enabled environment
</em>                               and provide users with a richer touch-enabled
<em>                               experience. You can also handle both events,
</em>                               separately, to provide a different response
<em>                               for a touch event than a mouse event.</p>
</em>
<em>                               <p>When handling the properties of the event
</em>                               object, note that the <code>localX</code> and
<em>                               <code>localY</code> properties are set to the
</em>                               primary point of contact. The
<em>                               <code>offsetX</code> and <code>offsetY</code>
</em>                               properties are the distance to the point of
<em>                               contact where the swipe gesture is
</em>                               complete.</p>
<em>
</em>                               <p><b>Note:</b> While some devices using the
<em>                               Mac OS operating system can interpret a
</em>                               four-finger swipe, this API only supports a
<em>                               three-finger swipe.</p>
</em> @event gestureTwoFingerTap    Dispatched when the user presses two points
<em>                               of contact over the same InteractiveObject
</em>                               instance on a touch-enabled device(such as
<em>                               presses and releases two fingers over a
</em>                               display object on a mobile phone or tablet
<em>                               with a touch screen). Some devices might also
</em>                               interpret this contact as a
<em>                               <code>doubleClick</code> event.
</em>
<em>                               <p>Specifically, if a user taps two fingers
</em>                               over an InteractiveObject, the
<em>                               InteractiveObject instance can dispatch a
</em>                               <code>doubleClick</code> event or a
<em>                               <code>gestureTwoFingerTap</code> event, or
</em>                               both if the current environment supports it.
<em>                               Choose how you want to handle the user
</em>                               interaction. Use the openfl.ui.Multitouch
<em>                               class to manage touch event handling(enable
</em>                               touch gesture event handling, simple touch
<em>                               point event handling, or disable touch events
</em>                               so only mouse events are dispatched). If you
<em>                               choose to handle the <code>doubleClick</code>
</em>                               event, then the same event handler will run
<em>                               on a touch-enabled device and a mouse enabled
</em>                               device. However, if you choose to handle the
<em>                               <code>gestureTwoFingerTap</code> event, you
</em>                               can design your event handler to respond to
<em>                               the specific needs of a touch-enabled
</em>                               environment and provide users with a richer
<em>                               touch-enabled experience. You can also handle
</em>                               both events, separately, to provide a
<em>                               different response for a touch event than a
</em>                               mouse event.</p>
<em>
</em>                               <p><b>Note:</b> See the Multitouch class for
<em>                               environment compatibility information.</p>
</em> @event gestureZoom            Dispatched when the user performs a zoom
<em>                               gesture at a point of contact with an
</em>                               InteractiveObject instance(such as touching
<em>                               two fingers to a screen and then quickly
</em>                               spreading the fingers apart over a display
<em>                               object on a mobile phone or tablet with a
</em>                               touch screen). Moving fingers apart is a
<em>                               common zoom gesture, but each device and
</em>                               operating system can have its own
<em>                               requirements to indicate zoom. Some devices
</em>                               might also interpret this contact as a
<em>                               combination of several mouse events, as well.
</em>
<em>
</em>                               <p>Specifically, if a user moves a finger
<em>                               over an InteractiveObject, and then moves the
</em>                               fingers apart, the InteractiveObject instance
<em>                               can dispatch a <code>mouseOver</code> event
</em>                               and a <code>click</code> event(among
<em>                               others), in addition to the
</em>                               <code>gestureZoom</code> event, or all if the
<em>                               current environment supports it. Choose how
</em>                               you want to handle the user interaction. Use
<em>                               the openfl.ui.Multitouch class to manage touch
</em>                               event handling(enable touch gesture event
<em>                               handling, simple touch point event handling,
</em>                               or disable touch events so only mouse events
<em>                               are dispatched). If you choose to handle the
</em>                               <code>mouseOver</code> event, then the same
<em>                               event handler will run on a touch-enabled
</em>                               device and a mouse enabled device. However,
<em>                               if you choose to handle the
</em>                               <code>gestureZoom</code> event, you can
<em>                               design your event handler to respond to the
</em>                               specific needs of a touch-enabled environment
<em>                               and provide users with a richer touch-enabled
</em>                               experience. You can also handle both events,
<em>                               separately, to provide a different response
</em>                               for a touch event than a mouse event.</p>
<em>
</em>                               <p>When handling the properties of the event
<em>                               object, note that the <code>localX</code> and
</em>                               <code>localY</code> properties are set to the
<em>                               primary point of contact. The
</em>                               <code>offsetX</code> and <code>offsetY</code>
<em>                               properties are the distance to the point of
</em>                               contact where the zoom gesture is
<em>                               complete.</p>
</em>
<em>                               <p><b>Note:</b> See the Multitouch class for
</em>                               environment compatibility information.</p>
<em> @event imeStartComposition    This event is dispatched to any client app
</em>                               that supports inline input with an IME
<em> @event keyDown                Dispatched when the user presses a key.
</em>                               Mappings between keys and specific characters
<em>                               vary by device and operating system. This
</em>                               event type is generated after such a mapping
<em>                               occurs but before the processing of an input
</em>                               method editor(IME). IMEs are used to enter
<em>                               characters, such as Chinese ideographs, that
</em>                               the standard QWERTY keyboard is ill-equipped
<em>                               to produce. This event occurs before the
</em>                               <code>keyUp</code> event.
<em>
</em>                               <p>In AIR, canceling this event prevents the
<em>                               character from being entered into a text
</em>                               field.</p>
<em> @event keyFocusChange         Dispatched when the user attempts to change
</em>                               focus by using keyboard navigation. The
<em>                               default behavior of this event is to change
</em>                               the focus and dispatch the corresponding
<em>                               <code>focusIn</code> and
</em>                               <code>focusOut</code> events.
<em>
</em>                               <p>This event is dispatched to the object
<em>                               that currently has focus. The related object
</em>                               for this event is the InteractiveObject
<em>                               instance that receives focus if you do not
</em>                               prevent the default behavior. You can prevent
<em>                               the change in focus by calling the
</em>                               <code>preventDefault()</code> method in an
<em>                               event listener that is properly registered
</em>                               with the target object. Focus changes and
<em>                               <code>focusIn</code> and
</em>                               <code>focusOut</code> events are dispatched
<em>                               by default.</p>
</em> @event keyUp                  Dispatched when the user releases a key.
<em>                               Mappings between keys and specific characters
</em>                               vary by device and operating system. This
<em>                               event type is generated after such a mapping
</em>                               occurs but before the processing of an input
<em>                               method editor(IME). IMEs are used to enter
</em>                               characters, such as Chinese ideographs, that
<em>                               the standard QWERTY keyboard is ill-equipped
</em>                               to produce. This event occurs after a
<em>                               <code>keyDown</code> event and has the
</em>                               following characteristics:
<em> @event middleClick            Dispatched when a user presses and releases
</em>                               the middle button of the user's pointing
<em>                               device over the same InteractiveObject. For a
</em>                               <code>middleClick</code> event to occur, it
<em>                               must always follow this series of events in
</em>                               the order of occurrence:
<em>                               <code>middleMouseDown</code> event, then
</em>                               <code>middleMouseUp</code>. The target object
<em>                               must be identical for both of these events;
</em>                               otherwise the <code>middleClick</code> event
<em>                               does not occur. Any number of other mouse
</em>                               events can occur at any time between the
<em>                               <code>middleMouseDown</code> or
</em>                               <code>middleMouseUp</code> events; the
<em>                               <code>middleClick</code> event still occurs.
</em> @event middleMouseDown        Dispatched when a user presses the middle
<em>                               pointing device button over an
</em>                               InteractiveObject instance.
<em> @event middleMouseUp          Dispatched when a user releases the pointing
</em>                               device button over an InteractiveObject
<em>                               instance.
</em> @event mouseDown              Dispatched when a user presses the pointing
<em>                               device button over an InteractiveObject
</em>                               instance. If the target is a SimpleButton
<em>                               instance, the SimpleButton instance displays
</em>                               the <code>downState</code> display object as
<em>                               the default behavior. If the target is a
</em>                               selectable text field, the text field begins
<em>                               selection as the default behavior.
</em> @event mouseFocusChange       Dispatched when the user attempts to change
<em>                               focus by using a pointer device. The default
</em>                               behavior of this event is to change the focus
<em>                               and dispatch the corresponding
</em>                               <code>focusIn</code> and
<em>                               <code>focusOut</code> events.
</em>
<em>                               <p>This event is dispatched to the object
</em>                               that currently has focus. The related object
<em>                               for this event is the InteractiveObject
</em>                               instance that receives focus if you do not
<em>                               prevent the default behavior. You can prevent
</em>                               the change in focus by calling
<em>                               <code>preventDefault()</code> in an event
</em>                               listener that is properly registered with the
<em>                               target object. The <code>shiftKey</code>
</em>                               property is not used. Focus changes and
<em>                               <code>focusIn</code> and
</em>                               <code>focusOut</code> events are dispatched
<em>                               by default.</p>
</em> @event mouseMove              Dispatched when a user moves the pointing
<em>                               device while it is over an InteractiveObject.
</em>                               If the target is a text field that the user
<em>                               is selecting, the selection is updated as the
</em>                               default behavior.
<em> @event mouseOut               Dispatched when the user moves a pointing
</em>                               device away from an InteractiveObject
<em>                               instance. The event target is the object
</em>                               previously under the pointing device. The
<em>                               <code>relatedObject</code> is the object the
</em>                               pointing device has moved to. If the target
<em>                               is a SimpleButton instance, the button
</em>                               displays the <code>upState</code> display
<em>                               object as the default behavior.
</em>
<em>                               <p>The <code>mouseOut</code> event is
</em>                               dispatched each time the mouse leaves the
<em>                               area of any child object of the display
</em>                               object container, even if the mouse remains
<em>                               over another child object of the display
</em>                               object container. This is different behavior
<em>                               than the purpose of the <code>rollOut</code>
</em>                               event, which is to simplify the coding of
<em>                               rollover behaviors for display object
</em>                               containers with children. When the mouse
<em>                               leaves the area of a display object or the
</em>                               area of any of its children to go to an
<em>                               object that is not one of its children, the
</em>                               display object dispatches the
<em>                               <code>rollOut</code> event.The
</em>                               <code>rollOut</code> events are dispatched
<em>                               consecutively up the parent chain of the
</em>                               object, starting with the object and ending
<em>                               with the highest parent that is neither the
</em>                               root nor an ancestor of the
<em>                               <code>relatedObject</code>.</p>
</em> @event mouseOver              Dispatched when the user moves a pointing
<em>                               device over an InteractiveObject instance.
</em>                               The <code>relatedObject</code> is the object
<em>                               that was previously under the pointing
</em>                               device. If the target is a SimpleButton
<em>                               instance, the object displays the
</em>                               <code>overState</code> or
<em>                               <code>upState</code> display object,
</em>                               depending on whether the mouse button is
<em>                               down, as the default behavior.
</em>
<em>                               <p>The <code>mouseOver</code> event is
</em>                               dispatched each time the mouse enters the
<em>                               area of any child object of the display
</em>                               object container, even if the mouse was
<em>                               already over another child object of the
</em>                               display object container. This is different
<em>                               behavior than the purpose of the
</em>                               <code>rollOver</code> event, which is to
<em>                               simplify the coding of rollout behaviors for
</em>                               display object containers with children. When
<em>                               the mouse enters the area of a display object
</em>                               or the area of any of its children from an
<em>                               object that is not one of its children, the
</em>                               display object dispatches the
<em>                               <code>rollOver</code> event. The
</em>                               <code>rollOver</code> events are dispatched
<em>                               consecutively down the parent chain of the
</em>                               object, starting with the highest parent that
<em>                               is neither the root nor an ancestor of the
</em>                               <code>relatedObject</code> and ending with
<em>                               the object.</p>
</em> @event mouseUp                Dispatched when a user releases the pointing
<em>                               device button over an InteractiveObject
</em>                               instance. If the target is a SimpleButton
<em>                               instance, the object displays the
</em>                               <code>upState</code> display object. If the
<em>                               target is a selectable text field, the text
</em>                               field ends selection as the default behavior.
<em> @event mouseWheel             Dispatched when a mouse wheel is spun over an
</em>                               InteractiveObject instance. If the target is
<em>                               a text field, the text scrolls as the default
</em>                               behavior. Only available on Microsoft Windows
<em>                               operating systems.
</em> @event nativeDragComplete     Dispatched by the drag initiator
<em>                               InteractiveObject when the user releases the
</em>                               drag gesture.
<em>
</em>                               <p>The event's dropAction property indicates
<em>                               the action set by the drag target object; a
</em>                               value of "none"
<em>                              (<code>DragActions.NONE</code>) indicates
</em>                               that the drop was canceled or was not
<em>                               accepted.</p>
</em>
<em>                               <p>The <code>nativeDragComplete</code> event
</em>                               handler is a convenient place to update the
<em>                               state of the initiating display object, for
</em>                               example, by removing an item from a list(on
<em>                               a drag action of "move"), or by changing the
</em>                               visual properties.</p>
<em> @event nativeDragDrop         Dispatched by the target InteractiveObject
</em>                               when a dragged object is dropped on it and
<em>                               the drop has been accepted with a call to
</em>                               DragManager.acceptDragDrop().
<em>
</em>                               <p>Access the dropped data using the event
<em>                               object <code>clipboard</code> property.</p>
</em>
<em>                               <p>The handler for this event should set the
</em>                               <code>DragManager.dropAction</code> property
<em>                               to provide feedback to the initiator object
</em>                               about which drag action was taken. If no
<em>                               value is set, the DragManager will select a
</em>                               default value from the list of allowed
<em>                               actions.</p>
</em> @event nativeDragEnter        Dispatched by an InteractiveObject when a
<em>                               drag gesture enters its boundary.
</em>
<em>                               <p>Handle either the
</em>                               <code>nativeDragEnter</code> or
<em>                               <code>nativeDragOver</code> events to allow
</em>                               the display object to become the drop
<em>                               target.</p>
</em>
<em>                               <p>To determine whether the dispatching
</em>                               display object can accept the drop, check the
<em>                               suitability of the data in
</em>                               <code>clipboard</code> property of the event
<em>                               object, and the allowed drag actions in the
</em>                               <code>allowedActions</code> property.</p>
<em> @event nativeDragExit         Dispatched by an InteractiveObject when a
</em>                               drag gesture leaves its boundary.
<em> @event nativeDragOver         Dispatched by an InteractiveObject
</em>                               continually while a drag gesture remains
<em>                               within its boundary.
</em>
<em>                               <p><code>nativeDragOver</code> events are
</em>                               dispatched whenever the mouse is moved. On
<em>                               Windows and Mac, they are also dispatched on
</em>                               a short timer interval even when the mouse
<em>                               has not moved.</p>
</em>
<em>                               <p>Handle either the
</em>                               <code>nativeDragOver</code> or
<em>                               <code>nativeDragEnter</code> events to allow
</em>                               the display object to become the drop
<em>                               target.</p>
</em>
<em>                               <p>To determine whether the dispatching
</em>                               display object can accept the drop, check the
<em>                               suitability of the data in
</em>                               <code>clipboard</code> property of the event
<em>                               object, and the allowed drag actions in the
</em>                               <code>allowedActions</code> property.</p>
<em> @event nativeDragStart        Dispatched at the beginning of a drag
</em>                               operation by the InteractiveObject that is
<em>                               specified as the drag initiator in the
</em>                               DragManager.doDrag() call.
<em> @event nativeDragUpdate       Dispatched during a drag operation by the
</em>                               InteractiveObject that is specified as the
<em>                               drag initiator in the DragManager.doDrag()
</em>                               call.
<em>
</em>                               <p><code>nativeDragUpdate</code> events are
<em>                               not dispatched on Linux.</p>
</em> @event paste                  Dispatched when the user activates the
<em>                               platform-specific accelerator key combination
</em>                               for a paste operation or selects 'Paste' from
<em>                               the text context menu. This event is
</em>                               dispatched to the object that currently has
<em>                               focus. If the object that currently has focus
</em>                               is a TextField, the default behavior of this
<em>                               event is to cause the contents of the
</em>                               clipboard to be pasted into the text field at
<em>                               the current insertion point replacing any
</em>                               currently selected text in the text field.
<em> @event rightClick             Dispatched when a user presses and releases
</em>                               the right button of the user's pointing
<em>                               device over the same InteractiveObject. For a
</em>                               <code>rightClick</code> event to occur, it
<em>                               must always follow this series of events in
</em>                               the order of occurrence:
<em>                               <code>rightMouseDown</code> event, then
</em>                               <code>rightMouseUp</code>. The target object
<em>                               must be identical for both of these events;
</em>                               otherwise the <code>rightClick</code> event
<em>                               does not occur. Any number of other mouse
</em>                               events can occur at any time between the
<em>                               <code>rightMouseDown</code> or
</em>                               <code>rightMouseUp</code> events; the
<em>                               <code>rightClick</code> event still occurs.
</em> @event rightMouseDown         Dispatched when a user presses the pointing
<em>                               device button over an InteractiveObject
</em>                               instance.
<em> @event rightMouseUp           Dispatched when a user releases the pointing
</em>                               device button over an InteractiveObject
<em>                               instance.
</em> @event rollOut                Dispatched when the user moves a pointing
<em>                               device away from an InteractiveObject
</em>                               instance. The event target is the object
<em>                               previously under the pointing device or a
</em>                               parent of that object. The
<em>                               <code>relatedObject</code> is the object that
</em>                               the pointing device has moved to. The
<em>                               <code>rollOut</code> events are dispatched
</em>                               consecutively up the parent chain of the
<em>                               object, starting with the object and ending
</em>                               with the highest parent that is neither the
<em>                               root nor an ancestor of the
</em>                               <code>relatedObject</code>.
<em>
</em>                               <p>The purpose of the <code>rollOut</code>
<em>                               event is to simplify the coding of rollover
</em>                               behaviors for display object containers with
<em>                               children. When the mouse leaves the area of a
</em>                               display object or the area of any of its
<em>                               children to go to an object that is not one
</em>                               of its children, the display object
<em>                               dispatches the <code>rollOut</code> event.
</em>                               This is different behavior than that of the
<em>                               <code>mouseOut</code> event, which is
</em>                               dispatched each time the mouse leaves the
<em>                               area of any child object of the display
</em>                               object container, even if the mouse remains
<em>                               over another child object of the display
</em>                               object container.</p>
<em> @event rollOver               Dispatched when the user moves a pointing
</em>                               device over an InteractiveObject instance.
<em>                               The event target is the object under the
</em>                               pointing device or a parent of that object.
<em>                               The <code>relatedObject</code> is the object
</em>                               that was previously under the pointing
<em>                               device. The <code>rollOver</code> events are
</em>                               dispatched consecutively down the parent
<em>                               chain of the object, starting with the
</em>                               highest parent that is neither the root nor
<em>                               an ancestor of the <code>relatedObject</code>
</em>                               and ending with the object.
<em>
</em>                               <p>The purpose of the <code>rollOver</code>
<em>                               event is to simplify the coding of rollout
</em>                               behaviors for display object containers with
<em>                               children. When the mouse enters the area of a
</em>                               display object or the area of any of its
<em>                               children from an object that is not one of
</em>                               its children, the display object dispatches
<em>                               the <code>rollOver</code> event. This is
</em>                               different behavior than that of the
<em>                               <code>mouseOver</code> event, which is
</em>                               dispatched each time the mouse enters the
<em>                               area of any child object of the display
</em>                               object container, even if the mouse was
<em>                               already over another child object of the
</em>                               display object container. </p>
<em> @event selectAll              Dispatched when the user activates the
</em>                               platform-specific accelerator key combination
<em>                               for a select all operation or selects 'Select
</em>                               All' from the text context menu. This event
<em>                               is dispatched to the object that currently
</em>                               has focus. If the object that currently has
<em>                               focus is a TextField, the default behavior of
</em>                               this event is to cause all the contents of
<em>                               the text field to be selected.
</em> @event softKeyboardActivate   Dispatched immediately after the soft
<em>                               keyboard is raised.
</em> @event softKeyboardActivating Dispatched immediately before the soft
<em>                               keyboard is raised.
</em> @event softKeyboardDeactivate Dispatched immediately after the soft
<em>                               keyboard is lowered.
</em> @event tabChildrenChange      Dispatched when the value of the object's
<em>                               <code>tabChildren</code> flag changes.
</em> @event tabEnabledChange       Dispatched when the object's
<em>                               <code>tabEnabled</code> flag changes.
</em> @event tabIndexChange         Dispatched when the value of the object's
<em>                               <code>tabIndex</code> property changes.
</em> @event textInput              Dispatched when a user enters one or more
<em>                               characters of text. Various text input
</em>                               methods can generate this event, including
<em>                               standard keyboards, input method editors
</em>                              (IMEs), voice or speech recognition systems,
<em>                               and even the act of pasting plain text with
</em>                               no formatting or style information.
<em> @event touchBegin             Dispatched when the user first contacts a
</em>                               touch-enabled device(such as touches a
<em>                               finger to a mobile phone or tablet with a
</em>                               touch screen). Some devices might also
<em>                               interpret this contact as a
</em>                               <code>mouseDown</code> event.
<em>
</em>                               <p>Specifically, if a user touches a finger
<em>                               to a touch screen, the InteractiveObject
</em>                               instance can dispatch a
<em>                               <code>mouseDown</code> event or a
</em>                               <code>touchBegin</code> event, or both if the
<em>                               current environment supports it. Choose how
</em>                               you want to handle the user interaction. Use
<em>                               the openfl.ui.Multitouch class to manage touch
</em>                               event handling(enable touch gesture event
<em>                               handling, simple touch point event handling,
</em>                               or disable touch events so only mouse events
<em>                               are dispatched). If you choose to handle the
</em>                               <code>mouseDown</code> event, then the same
<em>                               event handler will run on a touch-enabled
</em>                               device and a mouse enabled device. However,
<em>                               if you choose to handle the
</em>                               <code>touchBegin</code> event, you can design
<em>                               your event handler to respond to the specific
</em>                               needs of a touch-enabled environment and
<em>                               provide users with a richer touch-enabled
</em>                               experience. You can also handle both events,
<em>                               separately, to provide a different response
</em>                               for a touch event than a mouse event.</p>
<em>
</em>                               <p><b>Note:</b> See the Multitouch class for
<em>                               environment compatibility information.</p>
</em> @event touchEnd               Dispatched when the user removes contact with
<em>                               a touch-enabled device(such as lifts a
</em>                               finger off a mobile phone or tablet with a
<em>                               touch screen). Some devices might also
</em>                               interpret this contact as a
<em>                               <code>mouseUp</code> event.
</em>
<em>                               <p>Specifically, if a user lifts a finger
</em>                               from a touch screen, the InteractiveObject
<em>                               instance can dispatch a <code>mouseUp</code>
</em>                               event or a <code>touchEnd</code> event, or
<em>                               both if the current environment supports it.
</em>                               Choose how you want to handle the user
<em>                               interaction. Use the openfl.ui.Multitouch
</em>                               class to manage touch event handling(enable
<em>                               touch gesture event handling, simple touch
</em>                               point event handling, or disable touch events
<em>                               so only mouse events are dispatched). If you
</em>                               choose to handle the <code>mouseUp</code>
<em>                               event, then the same event handler will run
</em>                               on a touch-enabled device and a mouse enabled
<em>                               device. However, if you choose to handle the
</em>                               <code>touchEnd</code> event, you can design
<em>                               your event handler to respond to the specific
</em>                               needs of a touch-enabled environment and
<em>                               provide users with a richer touch-enabled
</em>                               experience. You can also handle both events,
<em>                               separately, to provide a different response
</em>                               for a touch event than a mouse event.</p>
<em>
</em>                               <p><b>Note:</b> See the Multitouch class for
<em>                               environment compatibility information.</p>
</em> @event touchMove              Dispatched when the user moves the point of
<em>                               contact with a touch-enabled device(such as
</em>                               drags a finger across a mobile phone or
<em>                               tablet with a touch screen). Some devices
</em>                               might also interpret this contact as a
<em>                               <code>mouseMove</code> event.
</em>
<em>                               <p>Specifically, if a user moves a finger
</em>                               across a touch screen, the InteractiveObject
<em>                               instance can dispatch a
</em>                               <code>mouseMove</code> event or a
<em>                               <code>touchMove</code> event, or both if the
</em>                               current environment supports it. Choose how
<em>                               you want to handle the user interaction. Use
</em>                               the openfl.ui.Multitouch class to manage touch
<em>                               event handling(enable touch gesture event
</em>                               handling, simple touch point event handling,
<em>                               or disable touch events so only mouse events
</em>                               are dispatched). If you choose to handle the
<em>                               <code>mouseMove</code> event, then the same
</em>                               event handler will run on a touch-enabled
<em>                               device and a mouse enabled device. However,
</em>                               if you choose to handle the
<em>                               <code>touchMove</code> event, you can design
</em>                               your event handler to respond to the specific
<em>                               needs of a touch-enabled environment and
</em>                               provide users with a richer touch-enabled
<em>                               experience. You can also handle both events,
</em>                               separately, to provide a different response
<em>                               for a touch event than a mouse event.</p>
</em>
<em>                               <p><b>Note:</b> See the Multitouch class for
</em>                               environment compatibility information.</p>
<em> @event touchOut               Dispatched when the user moves the point of
</em>                               contact away from InteractiveObject instance
<em>                               on a touch-enabled device(such as drags a
</em>                               finger from one display object to another on
<em>                               a mobile phone or tablet with a touch
</em>                               screen). Some devices might also interpret
<em>                               this contact as a <code>mouseOut</code>
</em>                               event.
<em>
</em>                               <p>Specifically, if a user moves a finger
<em>                               across a touch screen, the InteractiveObject
</em>                               instance can dispatch a <code>mouseOut</code>
<em>                               event or a <code>touchOut</code> event, or
</em>                               both if the current environment supports it.
<em>                               Choose how you want to handle the user
</em>                               interaction. Use the openfl.ui.Multitouch
<em>                               class to manage touch event handling(enable
</em>                               touch gesture event handling, simple touch
<em>                               point event handling, or disable touch events
</em>                               so only mouse events are dispatched). If you
<em>                               choose to handle the <code>mouseOut</code>
</em>                               event, then the same event handler will run
<em>                               on a touch-enabled device and a mouse enabled
</em>                               device. However, if you choose to handle the
<em>                               <code>touchOut</code> event, you can design
</em>                               your event handler to respond to the specific
<em>                               needs of a touch-enabled environment and
</em>                               provide users with a richer touch-enabled
<em>                               experience. You can also handle both events,
</em>                               separately, to provide a different response
<em>                               for a touch event than a mouse event.</p>
</em>
<em>                               <p><b>Note:</b> See the Multitouch class for
</em>                               environment compatibility information.</p>
<em> @event touchOver              Dispatched when the user moves the point of
</em>                               contact over an InteractiveObject instance on
<em>                               a touch-enabled device(such as drags a
</em>                               finger from a point outside a display object
<em>                               to a point over a display object on a mobile
</em>                               phone or tablet with a touch screen). Some
<em>                               devices might also interpret this contact as
</em>                               a <code>mouseOver</code> event.
<em>
</em>                               <p>Specifically, if a user moves a finger
<em>                               over an InteractiveObject, the
</em>                               InteractiveObject instance can dispatch a
<em>                               <code>mouseOver</code> event or a
</em>                               <code>touchOver</code> event, or both if the
<em>                               current environment supports it. Choose how
</em>                               you want to handle the user interaction. Use
<em>                               the openfl.ui.Multitouch class to manage touch
</em>                               event handling(enable touch gesture event
<em>                               handling, simple touch point event handling,
</em>                               or disable touch events so only mouse events
<em>                               are dispatched). If you choose to handle the
</em>                               <code>mouseOver</code> event, then the same
<em>                               event handler will run on a touch-enabled
</em>                               device and a mouse enabled device. However,
<em>                               if you choose to handle the
</em>                               <code>touchOver</code> event, you can design
<em>                               your event handler to respond to the specific
</em>                               needs of a touch-enabled environment and
<em>                               provide users with a richer touch-enabled
</em>                               experience. You can also handle both events,
<em>                               separately, to provide a different response
</em>                               for a touch event than a mouse event.</p>
<em>
</em>                               <p><b>Note:</b> See the Multitouch class for
<em>                               environment compatibility information.</p>
</em> @event touchRollOut           Dispatched when the user moves the point of
<em>                               contact away from an InteractiveObject
</em>                               instance on a touch-enabled device(such as
<em>                               drags a finger from over a display object to
</em>                               a point outside the display object on a
<em>                               mobile phone or tablet with a touch screen).
</em>                               Some devices might also interpret this
<em>                               contact as a <code>rollOut</code> event.
</em>
<em>                               <p>Specifically, if a user moves a finger
</em>                               over an InteractiveObject, the
<em>                               InteractiveObject instance can dispatch a
</em>                               <code>rollOut</code> event or a
<em>                               <code>touchRollOut</code> event, or both if
</em>                               the current environment supports it. Choose
<em>                               how you want to handle the user interaction.
</em>                               Use the openfl.ui.Multitouch class to manage
<em>                               touch event handling(enable touch gesture
</em>                               event handling, simple touch point event
<em>                               handling, or disable touch events so only
</em>                               mouse events are dispatched). If you choose
<em>                               to handle the <code>rollOut</code> event,
</em>                               then the same event handler will run on a
<em>                               touch-enabled device and a mouse enabled
</em>                               device. However, if you choose to handle the
<em>                               <code>touchRollOut</code> event, you can
</em>                               design your event handler to respond to the
<em>                               specific needs of a touch-enabled environment
</em>                               and provide users with a richer touch-enabled
<em>                               experience. You can also handle both events,
</em>                               separately, to provide a different response
<em>                               for a touch event than a mouse event.</p>
</em>
<em>                               <p><b>Note:</b> See the Multitouch class for
</em>                               environment compatibility information.</p>
<em> @event touchRollOver          Dispatched when the user moves the point of
</em>                               contact over an InteractiveObject instance on
<em>                               a touch-enabled device(such as drags a
</em>                               finger from a point outside a display object
<em>                               to a point over a display object on a mobile
</em>                               phone or tablet with a touch screen). Some
<em>                               devices might also interpret this contact as
</em>                               a <code>rollOver</code> event.
<em>
</em>                               <p>Specifically, if a user moves a finger
<em>                               over an InteractiveObject, the
</em>                               InteractiveObject instance can dispatch a
<em>                               <code>rollOver</code> event or a
</em>                               <code>touchRollOver</code> event, or both if
<em>                               the current environment supports it. Choose
</em>                               how you want to handle the user interaction.
<em>                               Use the openfl.ui.Multitouch class to manage
</em>                               touch event handling(enable touch gesture
<em>                               event handling, simple touch point event
</em>                               handling, or disable touch events so only
<em>                               mouse events are dispatched). If you choose
</em>                               to handle the <code>rollOver</code> event,
<em>                               then the same event handler will run on a
</em>                               touch-enabled device and a mouse enabled
<em>                               device. However, if you choose to handle the
</em>                               <code>touchRollOver</code> event, you can
<em>                               design your event handler to respond to the
</em>                               specific needs of a touch-enabled environment
<em>                               and provide users with a richer touch-enabled
</em>                               experience. You can also handle both events,
<em>                               separately, to provide a different response
</em>                               for a touch event than a mouse event.</p>
<em>
</em>                               <p><b>Note:</b> See the Multitouch class for
<em>                               environment compatibility information.</p>
</em> @event touchTap               Dispatched when the user lifts the point of
<em>                               contact over the same InteractiveObject
</em>                               instance on which the contact was initiated
<em>                               on a touch-enabled device(such as presses
</em>                               and releases a finger from a single point
<em>                               over a display object on a mobile phone or
</em>                               tablet with a touch screen). Some devices
<em>                               might also interpret this contact as a
</em>                               <code>click</code> event.
<em>
</em>                               <p>Specifically, if a user taps a finger over
<em>                               an InteractiveObject, the InteractiveObject
</em>                               instance can dispatch a <code>click</code>
<em>                               event or a <code>touchTap</code> event, or
</em>                               both if the current environment supports it.
<em>                               Choose how you want to handle the user
</em>                               interaction. Use the openfl.ui.Multitouch
<em>                               class to manage touch event handling(enable
</em>                               touch gesture event handling, simple touch
<em>                               point event handling, or disable touch events
</em>                               so only mouse events are dispatched). If you
<em>                               choose to handle the <code>click</code>
</em>                               event, then the same event handler will run
<em>                               on a touch-enabled device and a mouse enabled
</em>                               device. However, if you choose to handle the
<em>                               <code>touchTap</code> event, you can design
</em>                               your event handler to respond to the specific
<em>                               needs of a touch-enabled environment and
</em>                               provide users with a richer touch-enabled
<em>                               experience. You can also handle both events,
</em>                               separately, to provide a different response
<em>                               for a touch event than a mouse event.</p>
</em>
<em>                               <p><b>Note:</b> See the Multitouch class for
</em>                               environment compatibility information.</p></p></div><div><h2>Sub classes:</h2><table class="table table-condensed"><tbody><tr><td width="200"><a href="/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages/openfl/display/DisplayObjectContainer.html">DisplayObjectContainer</a></td><td><p></p></td></tr><tr><td width="200"><a href="/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages/openfl/text/TextField.html">TextField</a></td><td><p></p></td></tr></tbody></table></div><h2>Instance Fields</h2><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="doubleClickEnabled"></a><h3><code><span class="keyword">var</span> <a href="#doubleClickEnabled"><span class="identifier">doubleClickEnabled</span></a>:<span class="type">Bool</span></code></h3><div class="doc"><p>Specifies whether the object receives <code>doubleClick</code> events. The
default value is <code>false</code>, which means that by default an
InteractiveObject instance does not receive <code>doubleClick</code>
events. If the <code>doubleClickEnabled</code> property is set to
<code>true</code>, the instance receives <code>doubleClick</code> events
within its bounds. The <code>mouseEnabled</code> property of the
InteractiveObject instance must also be set to <code>true</code> for the
object to receive <code>doubleClick</code> events.
*
<p>No event is dispatched by setting this property. You must use the
<code>addEventListener()</code> method to add an event listener for the
<code>doubleClick</code> event.</p></p></div></div><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="focusRect"></a><h3><code><span class="keyword">var</span> <a href="#focusRect"><span class="identifier">focusRect</span></a>:<span class="type">Dynamic</span></code></h3><div class="doc"><p></p></div></div><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="mouseEnabled"></a><h3><code><span class="keyword">var</span> <a href="#mouseEnabled"><span class="identifier">mouseEnabled</span></a>:<span class="type">Bool</span></code></h3><div class="doc"><p>Specifies whether this object receives mouse, or other user input,
messages. The default value is <code>true</code>, which means that by
default any InteractiveObject instance that is on the display list
receives mouse events or other user input events. If
<code>mouseEnabled</code> is set to <code>false</code>, the instance does
not receive any mouse events(or other user input events like keyboard
events). Any children of this instance on the display list are not
affected. To change the <code>mouseEnabled</code> behavior for all
children of an object on the display list, use
<code>openfl.display.DisplayObjectContainer.mouseChildren</code>.
*
<p> No event is dispatched by setting this property. You must use the
<code>addEventListener()</code> method to create interactive
functionality.</p></p></div></div><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="needsSoftKeyboard"></a><h3><code><span class="keyword">var</span> <a href="#needsSoftKeyboard"><span class="identifier">needsSoftKeyboard</span></a>:<span class="type">Bool</span></code></h3><div class="doc"><p>Specifies whether a virtual keyboard(an on-screen, software keyboard)
should display when this InteractiveObject instance receives focus.
<em>
<p>By default, the value is <code>false</code> and focusing an
InteractiveObject instance does not raise a soft keyboard. If the
<code>needsSoftKeyboard</code> property is set to <code>true</code>, the
runtime raises a soft keyboard when the InteractiveObject instance is
ready to accept user input. An InteractiveObject instance is ready to
accept user input after a programmatic call to set the Stage
<code>focus</code> property or a user interaction, such as a "tap." If the
client system has a hardware keyboard available or does not support
virtual keyboards, then the soft keyboard is not raised.</p>
</em>
<p>The InteractiveObject instance dispatches
<code>softKeyboardActivating</code>, <code>softKeyboardActivate</code>,
and <code>softKeyboardDeactivate</code> events when the soft keyboard
raises and lowers.</p>
*
<p><b>Note:</b> This property is not supported in AIR applications on
iOS.</p></p></div></div><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="softKeyboardInputAreaOfInterest"></a><h3><code><span class="keyword">var</span> <a href="#softKeyboardInputAreaOfInterest"><span class="identifier">softKeyboardInputAreaOfInterest</span></a>:<a class="type" href="/home/joshua/TeamCity/buildAgent/work/c21abf6a7ac1a181/openfl/documentation/pages/openfl/geom/Rectangle.html">Rectangle</a></code></h3><div class="doc"><p></p></div></div><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="tabEnabled"></a><h3><code><span class="keyword">var</span> <a href="#tabEnabled"><span class="identifier">tabEnabled</span></a>:<span class="type">Bool</span></code></h3><div class="doc"><p></p></div></div><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="tabIndex"></a><h3><code><span class="keyword">var</span> <a href="#tabIndex"><span class="identifier">tabIndex</span></a>:<span class="type">Int</span></code></h3><div class="doc"><p></p></div></div><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="new"></a><h3><code><span class="keyword">function</span> <a href="#new"><span class="identifier">new</span></a>():<span class="type">Void</span></code></h3><div class="doc"><p>Calling the <code>new InteractiveObject()</code> constructor throws an
<code>ArgumentError</code> exception. You can, however, call constructors
for the following subclasses of InteractiveObject:
<ul>
<li><code>new SimpleButton()</code></li>
<li><code>new TextField()</code></li>
<li><code>new Loader()</code></li>
<li><code>new Sprite()</code></li>
<li><code>new MovieClip()</code></li>
</ul></p></div></div><div class="platform platform-Linux platform-Mac platform-Tizen platform-Android platform-Windows platform-iOS platform-Flash platform-BlackBerry platform-Firefox platform-HTML5"><a name="requestSoftKeyboard"></a><h3><code><span class="keyword">function</span> <a href="#requestSoftKeyboard"><span class="identifier">requestSoftKeyboard</span></a>():<span class="type">Bool</span></code></h3><div class="doc"><p>Raises a virtual keyboard.
<em>
</em> <p>Calling this method focuses the InteractiveObject instance and raises
<em> the soft keyboard, if necessary. The <code>needsSoftKeyboard</code> must
</em> also be <code>true</code>. A keyboard is not raised if a hardware keyboard
<em> is available, or if the client system does not support virtual
</em> keyboards.</p>
<em>
</em> <p><b>Note:</b> This method is not supported in AIR applications on
<em> iOS.</p>
</em> 
<em> @return A value of <code>true</code> means that the soft keyboard request
</em>         was granted; <code>false</code> means that the soft keyboard was
*         not raised.</p></div></div></div></div></div></body></html>